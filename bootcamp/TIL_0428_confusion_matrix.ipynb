{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오차행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![confusion_matrix](./confusion_matrix.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TN : 예측값을 Negative 값 0으로 예측했고, 실제 값 역시 Negative 값 0\n",
    "* FP : 예측값을 Positive 값 1로 예측했는데, 실제 값은 Negative 값 0\n",
    "* FN : 예측값을 Negative 값 0으로 예측했는데, 실제 값은 Positive 값 1\n",
    "* TP : 예측값을 Positive 값 1로 예측했는데, 실제 값 역시 Positive 값 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 (Accuracy)\n",
    "* 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수\n",
    "* accuracy : (TN + TP) / (TN + FP + FN+TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도 (Precision) = TP / (FP + TP)\n",
    "* 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율 \n",
    "* 공식의 분모인 FP + TP는 예측을 Positive로 한 모든 데이터 건수이며, 분자 TP는 예측과 실제 값이 Positive로 일치한 건수\n",
    "* Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측도라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 재현율 (Recall) = TP / (FN + TP)\n",
    "* 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율\n",
    "* 분모는 실제 값이 Positive인 모든 데이터 건수이며, 분자 TP는 예측과 실제 값이 Positive로 일치한 데이터 건수 \n",
    "* 민감도(Sensitivity) 또는 TPR(True Positive Rate)라고 부른다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정밀도/재현율 트레이드 오프 Trade-off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 분류하려는 업무의 특성상 정밀도 또는 재현율이 특별히 강조해야 할 경우, 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다.\n",
    "* 하지만 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치가 떨어지기 쉽다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wisc_bc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M : 양성, B : 음성 \n",
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266           0.1242   \n",
       "1       424.8            0.1213             0.2515           0.1916   \n",
       "2       471.4            0.1369             0.1482           0.1067   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df.drop(['id', 'diagnosis'], axis=1)\n",
    "X_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(X_data, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LimDongKyu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(train_input, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577464788732394\n",
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "print (lr.score(train_input, train_target))\n",
    "print (lr.score(test_input, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99684621, 0.00315379],\n",
       "       [0.68454368, 0.31545632],\n",
       "       [0.90429906, 0.09570094],\n",
       "       [0.00001922, 0.99998078],\n",
       "       [0.00168031, 0.99831969],\n",
       "       [0.99268863, 0.00731137],\n",
       "       [0.00000002, 0.99999998],\n",
       "       [0.99569616, 0.00430384],\n",
       "       [0.99793331, 0.00206669],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00002748, 0.99997252],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00799707, 0.99200293],\n",
       "       [0.78516549, 0.21483451],\n",
       "       [0.0010242 , 0.9989758 ],\n",
       "       [0.99055951, 0.00944049],\n",
       "       [0.99999575, 0.00000425],\n",
       "       [0.99556693, 0.00443307],\n",
       "       [0.13458825, 0.86541175],\n",
       "       [0.97635114, 0.02364886],\n",
       "       [0.00000002, 0.99999998],\n",
       "       [0.00545537, 0.99454463],\n",
       "       [0.00000001, 0.99999999],\n",
       "       [0.00180344, 0.99819656],\n",
       "       [0.996582  , 0.003418  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9864862 , 0.0135138 ],\n",
       "       [0.98717373, 0.01282627],\n",
       "       [0.99781675, 0.00218325],\n",
       "       [0.99989684, 0.00010316],\n",
       "       [0.99895175, 0.00104825],\n",
       "       [0.99706768, 0.00293232],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99481922, 0.00518078],\n",
       "       [0.00000005, 0.99999995],\n",
       "       [0.99867114, 0.00132886],\n",
       "       [0.96000474, 0.03999526],\n",
       "       [0.99946359, 0.00053641],\n",
       "       [0.99288509, 0.00711491],\n",
       "       [0.95310724, 0.04689276],\n",
       "       [0.99956826, 0.00043174],\n",
       "       [0.01442279, 0.98557721],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99410027, 0.00589973],\n",
       "       [0.98262382, 0.01737618],\n",
       "       [0.58748818, 0.41251182],\n",
       "       [0.98351612, 0.01648388],\n",
       "       [0.00006162, 0.99993838],\n",
       "       [0.00001421, 0.99998579],\n",
       "       [0.98893504, 0.01106496],\n",
       "       [0.9964053 , 0.0035947 ],\n",
       "       [0.99813935, 0.00186065],\n",
       "       [0.99792782, 0.00207218],\n",
       "       [0.00000008, 0.99999992],\n",
       "       [0.89113248, 0.10886752],\n",
       "       [0.98307977, 0.01692023],\n",
       "       [0.10071451, 0.89928549],\n",
       "       [0.00000424, 0.99999576],\n",
       "       [0.0013943 , 0.9986057 ],\n",
       "       [0.98970936, 0.01029064],\n",
       "       [0.97652375, 0.02347625],\n",
       "       [0.9980672 , 0.0019328 ],\n",
       "       [0.00121909, 0.99878091],\n",
       "       [0.00488212, 0.99511788],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99373569, 0.00626431],\n",
       "       [0.00001042, 0.99998958],\n",
       "       [0.96875053, 0.03124947],\n",
       "       [0.00102998, 0.99897002],\n",
       "       [0.98849493, 0.01150507],\n",
       "       [0.98512981, 0.01487019],\n",
       "       [0.99568551, 0.00431449],\n",
       "       [0.98540888, 0.01459112],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9794271 , 0.0205729 ],\n",
       "       [0.9882041 , 0.0117959 ],\n",
       "       [0.02096473, 0.97903527],\n",
       "       [0.90611987, 0.09388013],\n",
       "       [0.94080485, 0.05919515],\n",
       "       [0.99963296, 0.00036704],\n",
       "       [0.99677137, 0.00322863],\n",
       "       [0.86336483, 0.13663517],\n",
       "       [0.00000016, 0.99999984],\n",
       "       [0.60028082, 0.39971918],\n",
       "       [0.99786068, 0.00213932],\n",
       "       [0.99761408, 0.00238592],\n",
       "       [0.57884036, 0.42115964],\n",
       "       [0.0000001 , 0.9999999 ],\n",
       "       [0.99225213, 0.00774787],\n",
       "       [0.90169359, 0.09830641],\n",
       "       [0.24952286, 0.75047714],\n",
       "       [0.9867713 , 0.0132287 ],\n",
       "       [0.99981543, 0.00018457],\n",
       "       [0.93836403, 0.06163597],\n",
       "       [0.99976795, 0.00023205],\n",
       "       [0.99722615, 0.00277385],\n",
       "       [0.99893432, 0.00106568],\n",
       "       [0.89854165, 0.10145835],\n",
       "       [0.99870125, 0.00129875],\n",
       "       [0.00001632, 0.99998368],\n",
       "       [0.99687889, 0.00312111],\n",
       "       [0.00077248, 0.99922752],\n",
       "       [0.97678121, 0.02321879],\n",
       "       [0.94453426, 0.05546574],\n",
       "       [0.9996073 , 0.0003927 ],\n",
       "       [0.9982498 , 0.0017502 ],\n",
       "       [0.99960747, 0.00039253],\n",
       "       [0.98188597, 0.01811403],\n",
       "       [0.94122648, 0.05877352],\n",
       "       [0.95966091, 0.04033909],\n",
       "       [0.94097546, 0.05902454],\n",
       "       [0.10501943, 0.89498057],\n",
       "       [0.99091031, 0.00908969],\n",
       "       [0.00016943, 0.99983057],\n",
       "       [0.55755202, 0.44244798],\n",
       "       [0.9987035 , 0.0012965 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94795783, 0.05204217],\n",
       "       [0.99344914, 0.00655086],\n",
       "       [0.99852546, 0.00147454],\n",
       "       [0.91800785, 0.08199215],\n",
       "       [0.00000011, 0.99999989],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00000204, 0.99999796],\n",
       "       [0.96958055, 0.03041945],\n",
       "       [0.99933239, 0.00066761],\n",
       "       [0.91770422, 0.08229578],\n",
       "       [0.9989733 , 0.0010267 ],\n",
       "       [0.94874879, 0.05125121],\n",
       "       [0.99813749, 0.00186251],\n",
       "       [0.00000079, 0.99999921],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98087636, 0.01912364],\n",
       "       [0.99802525, 0.00197475],\n",
       "       [0.99548651, 0.00451349],\n",
       "       [0.93378044, 0.06621956],\n",
       "       [0.99406627, 0.00593373],\n",
       "       [0.98972774, 0.01027226],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0000051 , 0.9999949 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "lr.predict_proba(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91,  1],\n",
       "       [ 3, 48]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_target, lr.predict(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.972027972027972\n",
      "accuracy : 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : {}'.format(accuracy_score(test_target, lr.predict(test_input))))\n",
    "print('accuracy :', (91 + 48)  /  (91 + 1 + 3 + 48)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.9795918367346939\n",
      "precision : 0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "print('precision : {}'.format(precision_score(test_target, lr.predict(test_input))))\n",
    "print('precision :', 48 / (1 + 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 0.9411764705882353\n",
      "recall : 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "print('recall : {}'.format(recall_score(test_target, lr.predict(test_input))))\n",
    "print('recall :', 48 / (3 + 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85,  7],\n",
       "       [ 0, 51]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "custom_threshold = 0.1\n",
    "pred_proba_1 = lr.predict_proba(test_input)[:,-1].reshape(-1,1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "confusion_matrix(test_target, custom_predict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92  0]\n",
      " [ 6 45]]\n",
      "1.0\n",
      "0.8823529411764706\n",
      "[[91  1]\n",
      " [ 4 47]]\n",
      "0.9791666666666666\n",
      "0.9215686274509803\n",
      "[[91  1]\n",
      " [ 3 48]]\n",
      "0.9795918367346939\n",
      "0.9411764705882353\n",
      "[[91  1]\n",
      " [ 3 48]]\n",
      "0.9795918367346939\n",
      "0.9411764705882353\n",
      "[[91  1]\n",
      " [ 3 48]]\n",
      "0.9795918367346939\n",
      "0.9411764705882353\n",
      "[[90  2]\n",
      " [ 1 50]]\n",
      "0.9615384615384616\n",
      "0.9803921568627451\n",
      "[[89  3]\n",
      " [ 0 51]]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "[[88  4]\n",
      " [ 0 51]]\n",
      "0.9272727272727272\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for thre in [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]:\n",
    "    custom_threshold = thre\n",
    "    pred_proba_1 = lr.predict_proba(test_input)[:,-1].reshape(-1,1)\n",
    "    binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
    "    custom_predict = binarizer.transform(pred_proba_1)\n",
    "    print (confusion_matrix(test_target, custom_predict ))\n",
    "    print (precision_score(test_target, custom_predict ))\n",
    "    print (recall_score(test_target, custom_predict ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_curve_plot(test_target, lr.predict_proba(test_input)[:, 1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 스코어\n",
    "* 정밀도와 재현율을 결합한 지표\n",
    "* F1 스코어는 정밀도와 재현율이 어느 한 쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가진다\n",
    "* F1 Score : 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(test_target, lr.predict(test_input))\n",
    "recall = recall_score(test_target, lr.predict(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score : 0.96\n",
      "F1 score : 0.96\n"
     ]
    }
   ],
   "source": [
    "print('F1 score : {}'.format(f1_score(test_target, lr.predict(test_input))))\n",
    "print('F1 score : {}'.format( 2 * precision * recall / (precision + recall) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC 곡선과 AUC\n",
    "* ROC 곡선과 이에 기반한 AUC 스코어는 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표 \n",
    "* ROC 곡선(Receiver Operation Characteristic Curve)은 우리말로 수신자 판단 곡선\n",
    "    > 2차대전 때 통신 장비 성능 평가를 위해 고안된 수치\n",
    "    \n",
    "    > 의학 분야에서 많이 사용되고, 머신러닝의 이진 분류 모델의 예측 성능을 판단하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ROC 곡선은 FPR(False Positive Rate)이 변활 때 TPR(True Positive Rate)이 어떻게 변하하는지 나타내는 곡선\n",
    "* FPR을 X축으로, TPR을 Y축으로 잡으면 FPR의 변화에 따른 TPR의 변화가 곡선 형태로 나타남\n",
    "    > TPR : recall (민감도)\n",
    "    \n",
    "    > FPR : FP / (TN + FP) = 1 - TNR = 1 - 특이도\n",
    "\n",
    "    > TNR (특이도) : TN / (TN + FP)\n",
    "\n",
    "* ROC 곡선은 FPR을 0부터 1까지 변경하면서 TPR의 변화 값을 구한다\n",
    "* 가운데 직선에 가까울수록 성능이 떨어지고 멀어질수록 성능이 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC(Area Under Curve)\n",
    "* 일반적으로 ROC 곡선 자체는 FPR과 TPR의 변화 값을 보는 데 이용하며, 분류의 성능 지표로 사용되는 것은 ROC 곡선 면적에 기반한 AUC 값으로 결정\n",
    "* ROC 곡선 밑의 면적을 구하는 것으로, 일반적으로 1에 가까울수록 좋은 수치\n",
    "* AUC 수치가 커지려면, FPR이 작은 상태에서 얼마나 큰 TPR을 얻을 수 있는지가 중요합니다. \n",
    "* 가운데 직선에서 멀어지고 왼쪽 상단 모서리 쪽으로 가파르게 곡선이 이동할수록, 직사각형에 가까운 곡선이 되어, 면적이 1에 가까워지는 좋은 ROC AUC 성능 수치\n",
    "* 보통의 분류는 0.5이상의 AUC를 갖는다"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425a1af5f1e5390d8981f7ca16a01614bb8c35f7954543dfc17a8690ba4dff91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
