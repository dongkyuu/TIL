{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2개의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 은닉층(Hidden layer) : 입력층과 출력층 사이에 있는 모든 층\n",
    "* 은닉층에는 활성화 함수 존재\n",
    "    * 활성화 함수는 신경망 층의 선형 방정식의 계산 값에 적용하는 함수\n",
    "    * 은닉층의 활성화 함수는 비교적 자유롭다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망의 출력층 (분류 문제) : 시그모이드 함수 or 소프트맥스 함수\n",
    "    * 이진 분류 : 시그모이드 함수\n",
    "    * 다중 분류 : 소프트맥스 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀 신경망의 출력층 : 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다\n",
    "    * 출력층의 선형 방정식의 계산을 그대로 출력\n",
    "* 이렇게 하려면 Dense 층의 activation 매개변수에 아무런 값을 지정하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 코드를 보면, 출력층 이전의 뉴런의 갯수를 보면 10개보다 많다\n",
    "* 만약 은닉층의 뉴런이 10개보다 적다면 부족한 정보가 전달될 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층 신경망 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 아래와 같이 dense1과 dense2를 리스트 항목으로 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 층의 이름을 지정하지 않으면, dense라고 이름을 자동 생성 \n",
    "* 출력 크기 : None, 100 \n",
    "    * 첫 번째 차원 : 샘플의 개수\n",
    "    * 샘플의 개수가 아직 정의되어 있지 않기 때문에 None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fit() 메서드 : 훈련 데이터를 주입하면, 이 데이터를 한 번에 모두 사용하지 않고 잘게 나누어 여러 번 걸쳐 **미니배치 경사 하강법** 단계 수행 \n",
    "* 케라스의 기본 미니배치 크기 : 32\n",
    "    * fit() 메서드에서 batch_size 매개변수로 변경 가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 층을 추가하는 다른 방법\n",
    "* Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden1'),\n",
    "    keras.layers.Dense(100, activation='sigmoid',  name='hidden2'),\n",
    "    keras.layers.Dense(100, activation='relu',  name='hidden3'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " hidden3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential 클래스의 객체를 만들고, 이 객체의 add() 메서드를 호출하여 층을 추가하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = keras.Sequential()\n",
    "model_3.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model_3.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5632 - accuracy: 0.8095\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4076 - accuracy: 0.8541\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3738 - accuracy: 0.8652\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3505 - accuracy: 0.8732\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3331 - accuracy: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6810f9e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model_3.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 렐루 활성화 함수 (ReLU)\n",
    "* 렐루 함수 : 이미지 분류 모델의 은닉층에 많이 사용하는 활성화 함수 \n",
    "* 시그모이드 함수는 층이 많을수록 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려워진다\n",
    "    * 렐루함수는 이런 문제가 없으며 계산도 간단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Flatten 클래스 : 배치 차원을 제외하고, 나머지 입력 차원을 모두 일렬로 펼치는 역할만 수행\n",
    "    * 곱해지는 가중치나 절편 X \n",
    "* Flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가\n",
    "    * Flatten 층은 다음 코드처럼 입력층 바로 뒤에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = keras.Sequential()\n",
    "model_relu.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model_relu.add(keras.layers.Dense(100, activation='relu'))\n",
    "model_relu.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 다시 수행\n",
    "\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5282 - accuracy: 0.8134\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3888 - accuracy: 0.8618\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3527 - accuracy: 0.8721\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3319 - accuracy: 0.8808\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3177 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e68a521460>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model_relu.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3794 - accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37936070561408997, 0.8730000257492065]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저\n",
    "* 케라스는 기본적으로 미니배치 경사 하강법을 사용하며 미니배치 개수는 32개 \n",
    "* fit() 메서드의 batch_size 매개변수에서 이를 조정 가능 \n",
    "* 케라스의 기본 경사 하강법 알고리즘인 **RMSprop** 사용\n",
    "* 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공. 이들을 옵티마이저(Optimizer)라고 한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD()\n",
    "model_relu.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 옵티마이저의 SGD 클래스를 사용하면 학습률등, 파라미터 값을 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기본 경사 하강법 옵티마이저 : 모두 SGD 클래스에서 제공\n",
    "    * SGD 클래스의 momentum 매개변수의 기본값 : 0\n",
    "    * 0보다 큰 값으로 지정 : 마치 이전의 그레디언트를 가속도처럼 사용하는 모멘텀 최적화(momentum optimization) 사용\n",
    "* 보통 momentum 매개변수는 0.9 이상을 지정\n",
    "* SGD 클래스의 nesterov 매개변수를 기본값으로 False에서 True로 변경 : 네스테로프 모멘텀 최적화(네스테로프 가속 경사) 사용\n",
    "* 네스테로프 모멘텀 : 모멘텀 최적화를 2번 반복하여 구현 \n",
    "    * 대부분의 경우 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다\n",
    "    * 이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높다\n",
    "    * 이런 학습률을 **적응적 학습률(adaptive learning rate)** 이라고 한다\n",
    "    * 이런 방식들은 학습률 매개변수를 튜닝하는 수고를 덜 수 있는 것이 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 적응적 학습률을 사용하는 대표적인 옵티마이저 : Adagrad,  RMSprop \n",
    "* 각각 compile() 메서드의 optimizer 매개변수에 'adagrad'와 'rmsprop'으로 지정\n",
    "    * 기본값으로 rmsprop이 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad = keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = keras.Sequential()\n",
    "model_relu.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model_relu.add(keras.layers.Dense(100, activation='relu'))\n",
    "model_relu.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5316 - accuracy: 0.8125\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3948 - accuracy: 0.8587\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3566 - accuracy: 0.8717\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3326 - accuracy: 0.8808\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3198 - accuracy: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e68010b880>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model_relu.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3787129819393158, 0.8734166622161865]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_relu.evaluate(val_scaled, val_target)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ef078467dd63487d90c66fda3d945ae0cf08fcbb11ad780475c9b39620e3c77"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
